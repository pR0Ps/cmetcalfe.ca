<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Carey Metcalfe">
  <meta name="description" content="Posts tagged with 'website' on this site">

  <link rel="stylesheet" type="text/css" href="../../theme/css/styles.425931e9.min.css">

  <script src="../../theme/js/scripts.ab06d70e.min.js" type="text/javascript"></script>

  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">

  <link href="https://cmetcalfe.ca/feeds/all.rss" type="application/rss+xml" rel="alternate" title="Carey Metcalfe Full RSS Feed" />


  <title>Tag: website | Carey Metcalfe</title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-28306875-1', 'cmetcalfe.ca');
  ga('send', 'pageview');
</script>
</head>

<body>
  <aside>
    <div id="user_meta">
      <a href="../..">
        <img src="/images/avatar.jpg" id="logo">
      </a>
      <h2><a href="../.." class="nohover">Carey Metcalfe</a></h2>
      <p>Software Developer</p>
      <div class="social">
          <a data-email="ac.eflactemc@yerac:otliam" data-title="Email" title="You need javascript enabled to view this email" class="email" target="_blank" rel="noopener noreferrer"><i class="fa fa-envelope fa-lg"></i></a>
          <a href="https://github.com/pR0Ps" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fa fa-github fa-lg"></i></a>
          <a href="https://twitter.com/CareyMetcalfe" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fa fa-twitter fa-lg"></i></a>
      </div>
      <ul>
      </ul>
    </div>
  </aside>

  <main id="main">
    <header>
      <p id="header">
      <a href="../..">Home</a>

      &#124; <a href="../../blog/index.html">Blog</a>
      &#124; <a href="https://cmetcalfe.ca/feeds/all.rss">RSS Feed</a>
      </p>
<p>Tag: website
</p>
    </header>

<article>
  <div class="article_title">
    <h1><a href="../../blog/dynamic-dns-client-for-namecheap.html">Dynamic DNS client for Namecheap using bash & cron</a></h1>
  </div>
  <div class="article_text">
    <p>In addition to running this website, I also run a home server. For convenience,
I point a subdomain of <code>cmetcalfe.ca</code> at it so even though it's connected using
a dynamic IP (and actually seems to change fairly frequently), I can get access
to it from anywhere.</p>
<p>As a bit of background, the domain for this website is registered and managed
through <a href="http://namecheap.com">Namecheap</a>. While they do provide a <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/28">recommended DDNS client</a> for
keeping a domain's DNS updated, it only runs on Windows.</p>
<p>Instead, after <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/595">enabling DDNS for the domain</a> and reading <a href="https://www.namecheap.com/support/knowledgebase/article.aspx/29">Namecheap's article
on using the browser to update DDNS</a> I came up with the following <code>dns-update</code>
script.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="ch">#!/bin/sh</span>

<span class="c1"># Abort if anything goes wrong (negates the need for error-checking)</span>
<span class="nb">set</span> -e

<span class="c1"># Uses drill instead of dig</span>
resolve<span class="o">()</span> <span class="o">{</span>
    <span class="c1">#dig &quot;$1&quot; @resolver1.opendns.com +short 2&gt; /dev/null</span>
    <span class="nv">line</span><span class="o">=</span><span class="k">$(</span>drill <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> @resolver1.opendns.com <span class="m">2</span>&gt; /dev/null <span class="p">|</span> sed <span class="s1">&#39;/;;.*$/d;/^\s*$/d&#39;</span> <span class="p">|</span> grep <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span><span class="k">)</span>
    <span class="nb">echo</span> <span class="s2">&quot;</span><span class="nv">$line</span><span class="s2">&quot;</span> <span class="p">|</span> head -1 <span class="p">|</span> cut -f5
<span class="o">}</span>

<span class="nv">dns</span><span class="o">=</span><span class="k">$(</span>resolve &lt;subdomain&gt;.cmetcalfe.ca<span class="k">)</span>
<span class="nv">curr</span><span class="o">=</span><span class="k">$(</span>resolve myip.opendns.com<span class="k">)</span>
<span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$dns</span><span class="s2">&quot;</span> !<span class="o">=</span> <span class="s2">&quot;</span><span class="nv">$curr</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="k">if</span> curl -s <span class="s2">&quot;https://dynamicdns.park-your-domain.com/update?host=&lt;subdomain&gt;&amp;domain=cmetcalfe.ca&amp;password=&lt;my passkey&gt;&quot;</span> <span class="p">|</span> grep -q <span class="s2">&quot;&lt;ErrCount&gt;0&lt;/ErrCount&gt;&quot;</span><span class="p">;</span> <span class="k">then</span>
        <span class="nb">echo</span> <span class="s2">&quot;Server DNS record updated (</span><span class="nv">$dns</span><span class="s2"> -&gt; </span><span class="nv">$curr</span><span class="s2">)&quot;</span>
    <span class="k">else</span>
        <span class="nb">echo</span> <span class="s2">&quot;Server DNS record update FAILED (tried </span><span class="nv">$dns</span><span class="s2"> -&gt; </span><span class="nv">$curr</span><span class="s2">)&quot;</span>
    <span class="k">fi</span>
<span class="k">fi</span>
</code></pre></div>
</td></tr></table>
<p>It basically checks if the IP returned by a DNS query for the subdomain matches
the current IP of the server (as reported by an <a href="https://en.wikipedia.org/wiki/OpenDNS">OpenDNS</a> resolver) and if it
doesn't, sends a request to update the DNS. The <code>echo</code> commands are there just
to output some record of the IP changing. Maybe I'll do some analysis of it at
some point.</p>
<p>To run the script every 30 minutes and redirect any output from it to the
syslog, the following <a href="http://en.wikipedia.org/wiki/Cron">crontab</a> entry can be used:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>*/30 * * * * /path/to/dns-update <span class="p">|</span> /usr/bin/logger -t dns-update
</code></pre></div>
</td></tr></table>
<p>With the script automatically running every 30 minutes I can now be confident
that my subdomain will always be pointing at my home server whenever I need
access to it.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A previous version of this article used <code>curl -sf http://curlmyip.com</code> to
find the server's current IP address. However, after curlmyip went down for
a few days, I decided to take the advice in <a href="http://unix.stackexchange.com/a/81699">this StackExchange answer</a>
and use <a href="https://en.wikipedia.org/wiki/OpenDNS">OpenDNS</a> instead.</p>
</div>
  </div>
</article>
<hr />
<article>
  <div class="article_title">
    <h1><a href="../../blog/changes-to-the-blog-and-website.html">Changes to the blog and website</a></h1>
  </div>
  <div class="article_text">
    <p>I used to run this site on two different platforms.
There was a static landing page hosted on my server, and a blog hosted on <a href="http://blogger.com">Blogger</a>.</p>
<p>While the landing page was reasonably nice-looking (screenshot <a href="../../images/old_website_screenshot.png">here</a>), the blog looked terrible.
Free Blogger templates are generally not the nicest-looking things to look at and the one I used was no exception.</p>
<p>More importantly though, the Blogger composer made really hard to generate nice-looking articles.
For just writing text posts, it wasn't bad (aside from the crazy HTML it generated), but for inserting code
snippits or doing any kind of advanced formatting it was incredibly frustrating.</p>
<p>A few weeks ago I finally decided to deal with the situation. My general plan was to find a static site generator
that allowed for writing posts in <a href="http://daringfireball.net/projects/markdown">Markdown syntax</a> and use it to create a website that would
host some static content as well as the blog.</p>
<p>Static sites are exactly what they sound like. Just some static HTML files for a webserver to serve to clients.
No fancy frameworks, databases, or server-side processing involved. This is advantageous primarily because it
makes site blazing fast and very light on server resources.</p>
<p>After looking at a few static site generators, I decided to go with <a href="http://blog.getpelican.com">Pelican</a>.
Pelican is a Python-based static site generator that uses the awesome <a href="http://jinja.pocoo.org/docs">Jinja2</a> templating library
and understands content written in a number of formats, including Markdown.
It's extremely easy to set up and requires only a single command to regenerate the entire site.</p>
<p>Transferring content from the old blog into the *.md files that Pelican reads was also really simple.
Pelican includes a tool called <code>pelican-import</code> that allows for reading in data from a variety of sources.
I used this tool to pull all my previous posts down from the RSS feed of the old blog.</p>
<p>After fixing up the imported data (the import tool is good, but not perfect), I started looking into templates.</p>
<p>Like with Blogger themes, I was having a hard time finding anything I liked, until I came across a template called <a href="https://github.com/giulivo/pelican-svbhack">svbhack</a>.
It had a nice page layout and the general aesthetic was good, but needed a fair bit of tweaking.
I forked the repository (+1 for open-source) and over the next few weeks used my limited HTML and CSS knowledge to transform it into the one you see today.</p>
<p>There are still a bunch of things I want to change/fix/add, but at this point I feel that the site is ready to be released.
The code for the <a href="https://github.com/pR0Ps/pelican-svbhack">template</a> and the <a href="https://github.com/pR0Ps/website">site</a> is all freely availible on GitHub.</p>
<p>If you have any comments or suggestions I'd love to hear them!</p>
  </div>
</article>
<hr />
<article>
  <div class="article_title">
    <h1><a href="../../blog/how-to-download-an-entire-google-site.html">How to download an entire Google Site</a></h1>
  </div>
  <div class="article_text">
    <p>When using Google Sites, there is currently no way to make a backup of your
site, or download the site so you can host it on another server.  </p>
<p>This command uses a tool called <code>wget</code> to spider through a website
and download all the public files to the local computer. Unix users will
most likely have the wget tool already installed (if not, you can
install it via your preferred package manager), while Windows users can
get it from <a href="http://gnuwin32.sourceforge.net/packages/wget.htm">here</a>.  </p>
<p>Once wget is installed, run it with the following parameters:  </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1">#Downloads all public pages on a Google Site</span>

wget -e <span class="nv">robots</span><span class="o">=</span>off -m -k -K -E -rH -Dsites.google.com http://sites.google.com/a/domain/site/
</code></pre></div>
</td></tr></table>
<p>This tells wget to spider through all the links on your site and download
the html files and linked content (such as images). Note that pages that
aren't linked from anywhere on the site won't be downloaded.</p>
<p>This technique will also work for websites other than the ones hosted on Google Sites.</p>
  </div>
</article>

<footer>
<div id="paginator">
  <span id="left">
      <a href="../../blog/tags/website.html"><i class="fa fa-arrow-circle-left"></i> Prev</a>
  </span>
  <span id="right">
      <a href="../../blog/tags/website3.html">Next <i class="fa fa-arrow-circle-right"></i></a>
  </span>
  <div>
      <a href="../../blog/tags/website.html"> 1 </a>
      <a href="../../blog/tags/website2.html">[2]</a>
      <a href="../../blog/tags/website3.html"> 3 </a>
  </div>
</div>
</footer>

    <div id="ending_message">
        <p>&copy; Carey Metcalfe. Built using <a href="http://getpelican.com">Pelican</a>. Theme is <a href="https://github.com/pR0Ps/pelican-subtle">subtle</a> by <a href="http://cmetcalfe.ca">Carey Metcalfe</a>. Based on <a href="https://github.com/giulivo/pelican-svbhack">svbhack</a> by Giulio Fidente.</p>
    </div>
  </main>

  <script type="text/javascript">
    window.addEventListener('load', skipHeader)
  </script>

  <script type="text/javascript">
  window.addEventListener('load', unmangleEmail)
  </script>
</body>
</html>